<!DOCTYPE html>
<html lang="en-us" prefix="og: http://ogp.me/ns#"><head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	
	<link rel="icon" type="image/png" href="/favicon.ico">
	
	
	<title>Provisioned Concurrency: Avoiding Cold Starts in AWS Lambda | Mikhail Shilkov</title>
	
	
	
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.13.1/css/all.min.css" crossorigin="anonymous">
	<link href="https://fonts.googleapis.com/css?family=Righteous%7CMerriweather:300,300i,400,400i,700,700i" rel="stylesheet">
	
	<link rel="stylesheet" href="/sass/main.css">

	
	<link rel="canonical" href="https://www.pulumi.com/blog/aws-lambda-provisioned-concurrency-no-cold-starts/">
	
	
	<meta property="og:title" content="Provisioned Concurrency: Avoiding Cold Starts in AWS Lambda" />
	<meta property="og:description" content="AWS recently announced the launch of Provisioned Concurrency, a new feature of AWS Lambda that intends to solve the problem of cold starts." />
	<meta property="og:type" content="article" />
	<meta property="og:url" content="https://mikhail.io/2019/12/aws-lambda-provisioned-concurrency-no-cold-starts/" />

	
	
	
	
	<meta property="og:image" content="https://mikhail.io/2019/12/aws-lambda-provisioned-concurrency-no-cold-starts/teaser.png" />
	
	


	
	
	<meta property="article:tag" content="AWS" />
	
	<meta property="article:tag" content="Serverless" />
	
	<meta property="article:tag" content="AWS Lambda" />
	

	
	
	<meta name="twitter:card" content="summary_large_image"/>
	
	<meta name="twitter:image" content="https://mikhail.io/2019/12/aws-lambda-provisioned-concurrency-no-cold-starts/teaser.png" />
	
	

	<meta name="twitter:title" content="Provisioned Concurrency: Avoiding Cold Starts in AWS Lambda"/>
	<meta name="twitter:description" content="AWS recently announced the launch of Provisioned Concurrency, a new feature of AWS Lambda that intends to solve the problem of cold starts."/>
	<meta name="twitter:creator" content="@MikhailShilkov"></meta>
</head>
<body><script type="text/javascript" src="https://www.gstatic.com/charts/loader.js"></script>
<script type="text/javascript">
    google.charts.load("current", {packages:["corechart"]});
    function addChart(make) {
        google.charts.setOnLoadCallback(drawChart);
        function drawChart() {
            const data = new google.visualization.DataTable();

            const options = {
                height: 420,  
                chartArea: { width: '85%', height: '70%' },
                legend: 'none',
                hAxis: { minValue: 0 },
                vAxis: {},
                series: {      
                    0: { tooltip : false}
                }
            };
            const chart = make(data, options);
            options.hAxis.textStyle = options.hAxis.titleTextStyle 
                = options.vAxis.textStyle = options.vAxis.titleTextStyle = { fontName: 'Merriweather' };

            chart.draw(data, options);
        }
    }
</script>
<nav class="navbar navbar-expand-lg navbar-light bg-light">
    <div class="container pr-0">
        <a class="navbar-brand" href="/">
            <img class="author-thumb" src="/images/author.jpg" alt="Mikhail Shilkov">
            <span class="text-primary">Mikhail Shilkov</span>
        </a>

        
               


        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarMediumish" aria-controls="navbarSupportedContent"
            aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        
        <div class="collapse navbar-collapse" id="navbarMediumish">
            
            <ul class="navbar-nav ml-auto">
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/tags/">TOPICS</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/archives/">ARCHIVES</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/talks/">TALKS</a>
                </li>
                 
                <li class="nav-item ">
                    <a class="nav-link" href="/about/">ABOUT</a>
                </li>
                <li class="nav-item">
    <a class="nav-link" href="https://mikhail.io/feed/"><i class="fas fa-rss social-icon" aria-hidden="true"></i></a>
</li>

<li class="nav-item">
    <a class="nav-link" href="https://www.twitter.com/MikhailShilkov"><i class="fab fa-twitter social-icon" aria-hidden="true"></i></a>
</li>


<li class="nav-item">
    <a class="nav-link" href="https://dev.to/mikhailshilkov"><i class="fab fa-dev social-icon" aria-hidden="true"></i></a>
</li>


<li class="nav-item">
    <a class="nav-link" href="https://medium.com/@MikhailShilkov"><i class="fab fa-medium social-icon" aria-hidden="true"></i></a>
</li>


<li class="nav-item">
    <a class="nav-link" href="https://github.com/MikhailShilkov"><i class="fab fa-github social-icon" aria-hidden="true"></i></a>
</li>


<li class="nav-item">
    <a class="nav-link" href="https://www.linkedin.com/in/MikhailShilkov"><i class="fab fa-linkedin social-icon" aria-hidden="true"></i></a>
</li>

</ul>
        </div>
        
    </div>
</nav>


        <div class="container">

<div class="main-content">
    
    <div class="container">
        <div class="row">
            
            <div class="col-lg-2 pl-0"><div class="share">
    <ul>
        <li class="ml-1 mr-1" title="Say 'Thank You' for this article">
            <a href="#" onclick="heart();return false;">
                <i class="fas fa-heart" style="color: red"></i>
            </a>
            <div class="count" style="float: right; padding-left: .5em; padding-top: .25em" id="heartcount"></div>
        </li>

        <li class="ml-1 mr-1" title="Tweet this article">
            <a target="_blank"
                href="https://twitter.com/intent/tweet?text=Provisioned%20Concurrency%3a%20Avoiding%20Cold%20Starts%20in%20AWS%20Lambda%20by%20@MikhailShilkov&url=https%3a%2f%2fmikhail.io%2f2019%2f12%2faws-lambda-provisioned-concurrency-no-cold-starts%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=435');return false;">
                <i class="fab fa-twitter"></i>
            </a>
        </li>

        <li class="ml-1 mr-1" title="See the responses or write a response">
            <a href="#comments">
                <i class="fas fa-comment"></i>
            </a>
        </li>
    </ul>
</div></div>
            
            <div class="col-lg-9 flex-first flex-lg-unordered">

                <div class="mainheading">
                    
                    <h1 class="posttitle">Provisioned Concurrency: Avoiding Cold Starts in AWS Lambda</h1>
                    
                    <div class="post-top-meta">
                        <div>
                            
                                
                                <span class="post-date">Originally published on the <a
                                        href='https://www.pulumi.com/blog/aws-lambda-provisioned-concurrency-no-cold-starts/'>Pulumi Blog</a> on
                                    Dec 19, 2019
                                
                            
                            
                        &nbsp;&middot;&nbsp; 7 min read</span></span>
                        </div>
                    </div>
                </div>
                
                
                

                
                <div class="article-post">
                    <p>AWS recently <a href="https://aws.amazon.com/blogs/aws/new-provisioned-concurrency-for-lambda-functions/">announced</a> the launch of <strong>Provisioned Concurrency</strong>, a new feature of AWS Lambda that intends to solve the problem of cold starts. In this article, we take another look at the problem of latency-critical serverless applications, and how the new feature impacts the status-quo.</p>
<h2 id="concurrency-model-of-aws-lambda">Concurrency Model of AWS Lambda</h2>
<p>Despite being serverless, AWS Lambda uses lightweight containers to process incoming requests. Every container, or worker, can process only a single request at any given time.</p>
<figure >
    
        <img src="executions.png"
            alt="Overlapping executions land on separate workers"
             />
        
    
    <figcaption>
        <h4>Overlapping executions land on separate workers</h4>
    </figcaption>
    
</figure>
<p>Because of this, the number of concurrent requests defines the number of required workers that a specific AWS Lambda function needs to serve a response at any given moment.</p>
<h2 id="cold-starts">Cold Starts</h2>
<p>How does AWS know how many workers it needs to run for a given function? Well, it doesn&rsquo;t know in advance. AWS allocates new workers on-demand as the Lambda gets invoked.</p>
<p>Whenever Lambda receives a request but it has no idle workers, the control plane assigns a new generic worker to it. The worker then has to download the custom code or binaries of your Lambda and load them into memory before it can service the request. This process takes time, which significantly increases response latency.</p>
<p>The issue of sporadically slow responses caused by the need to increase the pool of workers is known as <strong>Cold Start</strong>. Cold starts are consistently the top concern about the applicability of serverless technologies to latency-sensitive workloads. There are numerous articles about the problem, including many articles I have written in the <a href="https://mikhail.io/serverless/coldstarts/">Cold Starts</a> section on my website</p>
<h2 id="warming">Warming</h2>
<p>Cold starts don&rsquo;t occur for the majority of requests because AWS Lambda reuses workers between subsequent invocations. However, if a particular worker is idle for too long (usually, several minutes), AWS may decide to recycle and return it to the generic pool.</p>
<p>A trick known as <strong>Lambda Warmers</strong> uses kept-alive workers to reduce the frequency of cold starts. The idea is to have a CloudWatch timer that fires every few minutes and sends <code>N</code> parallel requests to the target Lambda. If all those requests land at the same time, AWS has to provision at least <code>N</code> workers to process them. The actual operation doesn&rsquo;t have to do any useful work, but it resets the recycling timer back to zero.</p>
<p>There are a few drawbacks with this approach:</p>
<ul>
<li>If a valid request comes at the same time as warming requests, it might hit a cold start.</li>
<li>Extra logic is needed in the Lambda code to detect warming requests and short-circuit them instead of doing useful work.</li>
<li>CloudWatch rules require additional setup and management.</li>
<li>The result is still best-effort: Lambda still recycles workers from time to time.</li>
</ul>
<p>You can find more details about how Pulumi can help with some of these issues in <a href="https://mikhail.io/2018/08/aws-lambda-warmer-as-pulumi-component/">AWS Lambda Warmer as Pulumi Component</a>.</p>
<h2 id="provisioned-concurrency">Provisioned Concurrency</h2>
<p>At re:Invent 2019, AWS introduced Lambda <strong>Provisioned Concurrency</strong>&mdash;a feature to work around cold starts. The base concurrency model doesn&rsquo;t change. However, you can request a given number of workers to be always-warm and dedicated to a specific Lambda.</p>
<p>Here is an example of configuring the provisioned concurrency with Pulumi in TypeScript:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-ts" data-lang="ts"><span style="color:#00f">const</span> lambda = <span style="color:#00f">new</span> aws.lambda.Function(<span style="color:#a31515">&#34;mylambda&#34;</span>, {
    code: <span style="color:#2b91af">new</span> pulumi.asset.FileArchive(<span style="color:#a31515">&#34;./app&#34;</span>),
    handler: <span style="color:#a31515">&#34;handler&#34;</span>,
    role: <span style="color:#2b91af">role.arn</span>,
    publish: <span style="color:#2b91af">true</span>,
});

<span style="color:#00f">const</span> fixed = <span style="color:#00f">new</span> aws.lambda.ProvisionedConcurrencyConfig(<span style="color:#a31515">&#34;fixed-concurrency&#34;</span>, {
  functionName: <span style="color:#2b91af">lambda.name</span>,
  qualifier: <span style="color:#2b91af">lambda.version</span>,
  provisionedConcurrentExecutions: <span style="color:#2b91af">2</span>,
});
</code></pre></div><p>The snippet sets the provisioned concurrency for <code>mylambda</code> to a fixed value of <code>2</code>. Note that concurrency is provisioned per Lambda version, and it can&rsquo;t be set for the <code>$LATEST</code> version alias. Therefore, I set the <code>publish</code> attribute of my Lambda to <code>true</code> and reference a specific version of the Lambda in provisioning.</p>
<h2 id="dynamic-provisioned-concurrency">Dynamic Provisioned Concurrency</h2>
<p>A fixed level of provisioned concurrency works well for stable workloads.</p>
<figure >
    
        <img src="steady.png"
            alt="Fixed provisioned concurrency for uniform workloads"
             />
        
    
    <figcaption>
        <h4>Fixed provisioned concurrency for uniform workloads</h4>
    </figcaption>
    
</figure>
<p>However, many workloads fluctuate a lot. Extreme elasticity and lack of configuration parameters have always been the essential benefits of AWS Lambda. It works great if you can tolerate the cold starts that come during scale-out. If not, you can explore more advanced scenarios for provisioning concurrency dynamically.</p>
<p>Instead of choosing a permanently fixed value, you can configure provisioned concurrency to autoscale. The first required component is the autoscaling target:</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-ts" data-lang="ts"><span style="color:#00f">const</span> resourceId = pulumi.interpolate<span style="color:#a31515">`function:</span><span style="color:#a31515">${</span>lambda.name<span style="color:#a31515">}</span><span style="color:#a31515">:</span><span style="color:#a31515">${</span>lambda.version<span style="color:#a31515">}</span><span style="color:#a31515">`</span>;
<span style="color:#00f">const</span> target = <span style="color:#00f">new</span> aws.appautoscaling.Target(<span style="color:#a31515">&#34;target&#34;</span>, {
    resourceId,
    serviceNamespace: <span style="color:#a31515">&#34;lambda&#34;</span>,
    scalableDimension: <span style="color:#a31515">&#34;lambda:function:ProvisionedConcurrency&#34;</span>,
    minCapacity: <span style="color:#2b91af">1</span>,
    maxCapacity: <span style="color:#2b91af">10</span>,
});
</code></pre></div><p>The second component is the autoscaling policy, which defines the conditions when scaling starts. There are two important ways to adapt your concurrency provisioning to traffic patterns.</p>
<h3 id="scheduled-profile">Scheduled profile</h3>
<p>Quite often, increases in request rates are partially predictable. For example, usage increases during business hours and decreases at night.</p>
<figure >
    
        <img src="scheduled.png"
            alt="Provisioned concurrency matches predictable workload changes"
             />
        
    
    <figcaption>
        <h4>Provisioned concurrency matches predictable workload changes</h4>
    </figcaption>
    
</figure>
<p>The following snippet sets two scheduled rules that switch between two levels of provisioned concurrency every day.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-ts" data-lang="ts"><span style="color:#00f">function</span> scheduledConcurrency(name: <span style="color:#2b91af">string</span>, cron: <span style="color:#2b91af">string</span>, capacity: <span style="color:#2b91af">number</span>) {
    <span style="color:#00f">return</span> <span style="color:#00f">new</span> aws.appautoscaling.ScheduledAction(<span style="color:#a31515">`schedule-</span><span style="color:#a31515">${</span>name<span style="color:#a31515">}</span><span style="color:#a31515">`</span>, {
        resourceId,
        serviceNamespace: <span style="color:#a31515">&#34;lambda&#34;</span>,
        scalableDimension: <span style="color:#a31515">&#34;lambda:function:ProvisionedConcurrency&#34;</span>,
        scalableTargetAction: {
            minCapacity: <span style="color:#2b91af">capacity</span>,
            maxCapacity: <span style="color:#2b91af">capacity</span>,
        },
        schedule: <span style="color:#a31515">`cron(</span><span style="color:#a31515">${</span>cron<span style="color:#a31515">}</span><span style="color:#a31515">)`</span>,
    }, { dependsOn: [target]});
}

scheduledConcurrency(<span style="color:#a31515">&#34;day&#34;</span>, <span style="color:#a31515">&#34;0 8 * * ? *&#34;</span>, 10);
scheduledConcurrency(<span style="color:#a31515">&#34;night&#34;</span>, <span style="color:#a31515">&#34;0 18 * * ? *&#34;</span>, 2);
</code></pre></div><p>The example defines a helper function and calls it twice to set two schedules with different parameters.</p>
<h3 id="autoscaling-based-on-utilization">Autoscaling based on utilization</h3>
<p>If your workload pattern is less predictable, you can configure autoscaling for provisioned concurrency based on the measured utilization.</p>
<figure >
    
        <img src="variable.png"
            alt="Provisioned concurrency matches the variation in workload"
             />
        
    
    <figcaption>
        <h4>Provisioned concurrency matches the variation in workload</h4>
    </figcaption>
    
</figure>
<p>Here is a basic example of a dynamic scaling policy.</p>
<div class="highlight"><pre style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-ts" data-lang="ts"><span style="color:#00f">const</span> scaledConcurrency = <span style="color:#00f">new</span> aws.appautoscaling.Policy(<span style="color:#a31515">&#34;autoscaling&#34;</span>, {
    resourceId,
    serviceNamespace: <span style="color:#a31515">&#34;lambda&#34;</span>,
    scalableDimension: <span style="color:#a31515">&#34;lambda:function:ProvisionedConcurrency&#34;</span>,
    policyType: <span style="color:#a31515">&#34;TargetTrackingScaling&#34;</span>,
    targetTrackingScalingPolicyConfiguration: {
        targetValue: <span style="color:#2b91af">0.8</span>,
        predefinedMetricSpecification: {
            predefinedMetricType: <span style="color:#a31515">&#34;LambdaProvisionedConcurrencyUtilization&#34;</span>,
        },
    },
}, { dependsOn: [target]});
</code></pre></div><p>Currently, there are issues with autoscaling based on the metrics, which makes provisioned concurrency scale less effectively than what the chart above shows. Hopefully, Amazon will fix these issues soon.</p>
<h2 id="pricing">Pricing</h2>
<p>While hand-crafted Lambda warmers are virtually free, provisioned concurrency can be costly. The new pricing is an integral part of the change: Instead of purely per-call model, AWS charges per hour for provisioned capacity.</p>
<p>You would pay $0.015 per hour per GB of provisioned worker memory, even if a worker handled zero requests.</p>
<p>The per-invocation price gets a discount: $0.035 per GB-hour instead of the regular $0.06 per GB-hour. This change means that fully-utilized workers would be cheaper if provisioned compared to on-demand workers.</p>
<figure >
    
        <img src="pricing.png"
            alt="Comparison of the cost of a 1GB worker for two billing models"
             />
        
    
    <figcaption>
        <h4>Comparison of the cost of a 1GB worker for two billing models</h4>
    </figcaption>
    
</figure>
<p>The equilibrium point is at 60% utilization. Note that because the billed duration is rounded up to the nearest 100 ms for each execution, the utilization is not limited to 100%. A series of sequential executions can be processed by a single worker. If each execution is 10 ms, the charge is still 100 ms, and the total utilization can be as high as 1000% in terms of the chart above!</p>
<p>Finally, be careful to clean up your resources after any experiments: Leaving running workers with provisioned concurrency can be expensive! Using <code>pulumi destroy</code> removes resources after you finish experimenting.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Provisioned concurrency brings the long-awaited solution to cold starts in AWS Lambda. However, it comes at a cost in terms of a direct impact on billing and management overhead to provision concurrency at optimal levels.</p>
<p>For high-load functions where utilization is continuously above a known level of requests, it makes sense to set the provisioned concurrency to that level to save money and have the guarantee of warm workers.</p>
<p>If your Lambda hosts a latency-sensitive API, especially with runtimes like Java and .NET, you should strive to find the right balance between the percentage of requests that result in a cold start and the money spent on concurrency. Autoscaling should help once AWS has fixed the initial glitches that slipped into their current services.</p>
<p>If you want to try this for yourself, we&rsquo;ve updated the <a href="https://github.com/pulumi/examples/blob/master/aws-ts-serverless-raw/">Serverless App example</a> to show off the scenario of configurable AWS Lambda provisioned concurrency.</p>

                </div>

                
                <div class="after-post-tags">
                    <ul class="tags">
                        
                        <li>
                            
                            
                            <a href="/tags/aws">AWS</a>
                            
                        </li>
                        
                        <li>
                            
                            
                            <a href="/tags/serverless">Serverless</a>
                            
                        </li>
                        
                        <li>
                            
                            
                            <a href="/tags/aws-lambda">AWS Lambda</a>
                            
                        </li>
                        
                    </ul>
                </div>
                

                <hr/>

            </div>
            
        </div>
    </div>
    
    <div class="container">
    <div id="sharepane" class="row justify-content-center">
        <div class="col-md-2">

        </div>
        <div class="contact-intro col-md-2 text-center">
            <img class="profile-small d-inline-block mx-auto rounded-circle mb-3" height="100px"
                src="/images/author.jpg" alt="">
        </div>
        <div class="col-md-8">
            <section class="article-open_author">
                <div class="article-open_author_bio">
                    <h5 itemprop="author" itemscope="" itemtype="http://schema.org/Person">Author: Mikhail Shilkov</h5>
                    <p>
                        <div>Cloud developer and researcher.</div><div>Software engineer at Pulumi. Microsoft Azure MVP.</div>
                    </p>
                </div>
            </section>
            <a href="https://twitter.com/MikhailShilkov?ref_src=twsrc%5Etfw" class="twitter-follow-button" data-show-count="false">Follow @MikhailShilkov</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
        </div>
    </div>
</div>
<div class="container">
    <div id="comments" class="row justify-content-center mb-5">
        <div class="col-md-8">
            
            <div class="mb-5">
                <h5 class="float-left">Responses</h5>
                <div class="float-right"><a
                        href='https://github.com/mikhailshilkov/mikhailio-hugo/issues/27'>Write a
                        response</a></div>
            </div>
            <div id="gh-comments-list" style="display: none">27</div>
            <div class="mt-4">Visit the <b><a
                        href='https://github.com/mikhailshilkov/mikhailio-hugo/issues/27'>Github
                        Issue</a></b> to comment on this page</div>
            
        </div>
    </div>
</div>
</div>

        </div>
<footer class="footer">
    <div class="container">
        <div class="row">
            <div class="col-md-6 col-sm-6 text-center text-lg-left">
                &copy; Copyright Mikhail Shilkov - All rights reserved
            </div>
            <div class="col-md-6 col-sm-6 text-center text-lg-right">    
                
            </div>
        </div>
    </div>
</footer>











<script src="/js/bundle.min.js"></script>
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-59218480-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
    </body>
</html>
