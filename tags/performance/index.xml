<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Performance on Mikhail Shilkov</title>
    <link>https://mikhail.io/tags/performance/</link>
    <description>Recent content in Performance on Mikhail Shilkov</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Mikhail Shilkov - All rights reserved</copyright>
    <lastBuildDate>Tue, 25 May 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://mikhail.io/tags/performance/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Choosing the Number of Shards in Temporal History Service</title>
      <link>https://mikhail.io/2021/05/choose-the-number-of-shards-in-temporal-history-service/</link>
      <pubDate>Tue, 25 May 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2021/05/choose-the-number-of-shards-in-temporal-history-service/</guid>
      <description>&lt;p&gt;Today, I&amp;rsquo;m diving into the topic of tuning your Temporal clusters for optimal performance. More specifically, I will be discussing the single configuration option: the number of History service shards. Through a series of experiments, Iâ€™ll explain how a low number of shards can lead to contention, while a large number can cause excessive resource consumption.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Maru: Load Testing Tool for Temporal Workflows</title>
      <link>https://mikhail.io/2021/03/maru-load-testing-tool-for-temporal-workflows/</link>
      <pubDate>Thu, 18 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2021/03/maru-load-testing-tool-for-temporal-workflows/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://temporal.io&#34;&gt;Temporal&lt;/a&gt; enables developers to build highly reliable applications without having to worry about all the edge cases. If you are new to Temporal, check out my article &lt;a href=&#34;https://mikhail.io/2020/10/temporal-open-source-workflows-as-code/&#34;&gt;Open Source Workflows as Code&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Load-Testing Azure Functions with Loader.io</title>
      <link>https://mikhail.io/2019/07/load-testing-azure-functions-with-loaderio/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2019/07/load-testing-azure-functions-with-loaderio/</guid>
      <description>&lt;p&gt;When Azure Functions team presented the new &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/azure-functions/functions-premium-plan&#34;&gt;Premium plan&lt;/a&gt;, they made a series of demos which compared the response time of a Function App running on the Consumption plan vs. an App running on the Premium plan. Both apps would receive a rapid growth of incoming requests, and then the percentiles of response latencies were compared.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless at Scale: Serving StackOverflow-like Traffic</title>
      <link>https://mikhail.io/2019/serverless-at-scale-serving-stackoverflow-like-traffic/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2019/serverless-at-scale-serving-stackoverflow-like-traffic/</guid>
      <description>&lt;p&gt;Serverless compute is a very productive and quick way to get an application up and running. A developer writes a piece of code that solves a particular task and uploads it to the cloud. The provider handles code deployment and the ops burden of managing all the required infrastructure, so that the Function is always available, secure and performant.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From 0 to 1000 Instances: How Serverless Providers Scale Queue Processing</title>
      <link>https://mikhail.io/2018/11/from-0-to-1000-instances-how-serverless-providers-scale-queue-processing/</link>
      <pubDate>Mon, 19 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/11/from-0-to-1000-instances-how-serverless-providers-scale-queue-processing/</guid>
      <description>&lt;p&gt;Whenever I see a &amp;ldquo;Getting Started with Function-as-a-Service&amp;rdquo; tutorial, it usually shows off&#xA;a synchronous HTTP-triggered scenario. In my projects, though, I use a lot of asynchronous&#xA;functions triggered by a queue or an event stream.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Azure Functions V2 Is Released, How Performant Is It?</title>
      <link>https://mikhail.io/2018/10/azure-functions-v2-released-how-performant-is-it/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/10/azure-functions-v2-released-how-performant-is-it/</guid>
      <description>&lt;p&gt;Azure Functions major version 2.0 was released into GA a few days back during Microsoft Ignite. The runtime is now&#xA;based on .NET Core and thus is cross-platform and more interoperable. It has a nice extensibility story too.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless: Cold Start War</title>
      <link>https://mikhail.io/2018/08/serverless-cold-start-war/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/08/serverless-cold-start-war/</guid>
      <description>&lt;p&gt;&lt;em&gt;The newer and much more detailed cold start comparison is now available: &lt;a href=&#34;https://mikhail.io/serverless/coldstarts/&#34;&gt;Cold Starts in Serverless Functions&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Serverless cloud services are hot. Except when they are not :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cold Starts Beyond First Request in Azure Functions</title>
      <link>https://mikhail.io/2018/05/azure-functions-cold-starts-beyond-first-load/</link>
      <pubDate>Fri, 18 May 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/05/azure-functions-cold-starts-beyond-first-load/</guid>
      <description>&lt;p&gt;In my &lt;a href=&#34;https://mikhail.io/2018/04/azure-functions-cold-starts-in-numbers/&#34;&gt;previous article&lt;/a&gt;&#xA;I&amp;rsquo;ve explored the topic of Cold Starts in Azure Functions. Particularly, I&amp;rsquo;ve measured the&#xA;cold start delays per language and runtime version.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Azure Functions: Cold Starts in Numbers</title>
      <link>https://mikhail.io/2018/04/azure-functions-cold-starts-in-numbers/</link>
      <pubDate>Tue, 24 Apr 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/04/azure-functions-cold-starts-in-numbers/</guid>
      <description>&lt;p&gt;Auto-provisioning and auto-scalability are the killer features of Function-as-a-Service&#xA;cloud offerings, and Azure Functions in particular.&lt;/p&gt;&#xA;&lt;p&gt;One drawback of such dynamic provisioning is a phenomenon called &amp;ldquo;Cold Start&amp;rdquo;. Basically,&#xA;applications that haven&amp;rsquo;t been used for a while take longer to startup and to handle the&#xA;first request.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Load Testing Azure SQL Database by Copying Traffic from Production SQL Server</title>
      <link>https://mikhail.io/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server/</link>
      <pubDate>Tue, 06 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server/</guid>
      <description>&lt;p&gt;Azure SQL Database is a managed service that provides low-maintenance SQL Server instances in the cloud.&#xA;You don&amp;rsquo;t have to run and update VMs, or even take backups and setup failover clusters.&#xA;Microsoft will do administration for you, you just pay an hourly fee.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Event Sourcing: Optimizing NEventStore SQL read performance</title>
      <link>https://mikhail.io/2017/01/event-sourcing-optimizing-neventstore-sql-read-performance/</link>
      <pubDate>Sun, 29 Jan 2017 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2017/01/event-sourcing-optimizing-neventstore-sql-read-performance/</guid>
      <description>&lt;p&gt;In &lt;a href=&#34;https://mikhail.io/2016/11/event-sourcing-and-io-complexity/&#34;&gt;my previous post about Event Store read complexity&lt;/a&gt;&#xA;I described how the growth of reads from the event database might be&#xA;quadratic in respect to amount of events per aggregate.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SQL: produce resultset with N rows</title>
      <link>https://mikhail.io/2014/06/03/sql-produce-resultset-with-n-rows/</link>
      <pubDate>Tue, 03 Jun 2014 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2014/06/03/sql-produce-resultset-with-n-rows/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s talk about T-SQL today.&lt;/p&gt;&#xA;&lt;p&gt;Sometimes you need to produce a result set, which would contain N rows with numbers 1&amp;hellip;N in each row. For example, I needed to calculate some statistics per week for N weeks starting from today and going back to the past.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sgen to precompile classes for XmlSerializer</title>
      <link>https://mikhail.io/2014/05/21/sgen-to-precompile-classes-for-xmpserializer/</link>
      <pubDate>Wed, 21 May 2014 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2014/05/21/sgen-to-precompile-classes-for-xmpserializer/</guid>
      <description>&lt;p&gt;During my investigation of our ASP.NET application performance issue, I&amp;rsquo;ve found out that XmlSerializer may require a long warm-up. The first time, when it&amp;rsquo;s used for a specific class (de-)serialization, can take up to 500 ms om my machine! We use XmlSerializer to encode/decode user preferences. Having 40 different classes being deserialized at user login lead to a massive delay of 14 seconds. This is only for the first user login after the application start-up, but you do quite a lot of &amp;lsquo;first times&amp;rsquo; every day while developing the application.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
