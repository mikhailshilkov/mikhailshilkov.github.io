<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Google Cloud Functions on Mikhail Shilkov</title>
    <link>https://mikhail.io/tags/google-cloud-functions/</link>
    <description>Recent content in Google Cloud Functions on Mikhail Shilkov</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Mikhail Shilkov - All rights reserved</copyright>
    <lastBuildDate>Tue, 05 Jan 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://mikhail.io/tags/google-cloud-functions/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cold Starts in Google Cloud Functions</title>
      <link>https://mikhail.io/serverless/coldstarts/gcp/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/serverless/coldstarts/gcp/</guid>
      <description>&lt;p&gt;This article describes Google Cloud Functionsâ€”the dynamically scaled and billed-per-execution compute service. Instances of Cloud Functions are added and removed dynamically. When a new instance handles its first request, the response time suffers, which is called a &lt;strong&gt;cold start&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Comparison of Cold Starts in Serverless Functions across AWS, Azure, and GCP</title>
      <link>https://mikhail.io/serverless/coldstarts/big3/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/serverless/coldstarts/big3/</guid>
      <description>&lt;p&gt;This article compares Function-as-a-Service offerings of Big-3 cloud providers in terms of cold starts. AWS Lambda, Azure Functions (Consumption Plan), and Google Cloud Functions are all dynamically scaled and billed-per-execution compute services. Instances of cloud functions are added and removed dynamically. When a new instance handles its first request, the response time increases, which is called a &lt;strong&gt;cold start&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google Cloud Functions: Cold Start Duration per Instance Size</title>
      <link>https://mikhail.io/serverless/coldstarts/gcp/instances/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/serverless/coldstarts/gcp/instances/</guid>
      <description>&lt;p&gt;Google Cloud Functions have a setting to define the memory size that gets allocated to a single instance of a function. The CPU resources are allocated proportionally to the memory. So, in theory, larger instances could start faster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google Cloud Functions: Cold Start Duration per Language</title>
      <link>https://mikhail.io/serverless/coldstarts/gcp/languages/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/serverless/coldstarts/gcp/languages/</guid>
      <description>&lt;p&gt;The following chart shows the typical range of cold starts in Google Cloud Functions, broken down per language. The darker ranges are the most common 67% of durations, and lighter ranges include 95%.&lt;/p&gt;</description>
    </item>
    <item>
      <title>When Does Cold Start Happen on Google Cloud Functions?</title>
      <link>https://mikhail.io/serverless/coldstarts/gcp/intervals/</link>
      <pubDate>Tue, 05 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/serverless/coldstarts/gcp/intervals/</guid>
      <description>&lt;p&gt;The very first cold start happens when the very first request comes in after deployment.&lt;/p&gt;&#xA;&lt;p&gt;After that request is processed, the instance stays alive for the time being to be reused for subsequent requests. But for how long?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Less Frequent Cold Starts in Google Cloud Functions</title>
      <link>https://mikhail.io/2019/04/less-frequent-cold-starts-in-google-cloud-functions/</link>
      <pubDate>Sat, 27 Apr 2019 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2019/04/less-frequent-cold-starts-in-google-cloud-functions/</guid>
      <description>&lt;p&gt;Several days ago, I released an update to the &lt;a href=&#34;https://mikhail.io/serverless/coldstarts/&#34;&gt;Serverless Cold Starts&lt;/a&gt; section of my website. The most significant change to the previous dataset seems to be in how GCP treats idle instances of Google Cloud Functions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Visualizing Cold Starts</title>
      <link>https://mikhail.io/2019/03/visualizing-cold-starts/</link>
      <pubDate>Thu, 14 Mar 2019 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2019/03/visualizing-cold-starts/</guid>
      <description>&lt;p&gt;I &lt;a href=&#34;https://mikhail.io/serverless/coldstarts/&#34;&gt;wrote a lot&lt;/a&gt; about cold starts of serverless functions. The articles are full of charts and numbers which are hopefully useful but might be hard to internalize. I decided to come up with a way to represent colds starts visually.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless at Scale: Serving StackOverflow-like Traffic</title>
      <link>https://mikhail.io/2019/serverless-at-scale-serving-stackoverflow-like-traffic/</link>
      <pubDate>Mon, 21 Jan 2019 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2019/serverless-at-scale-serving-stackoverflow-like-traffic/</guid>
      <description>&lt;p&gt;Serverless compute is a very productive and quick way to get an application up and running. A developer writes a piece of code that solves a particular task and uploads it to the cloud. The provider handles code deployment and the ops burden of managing all the required infrastructure, so that the Function is always available, secure and performant.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From 0 to 1000 Instances: How Serverless Providers Scale Queue Processing</title>
      <link>https://mikhail.io/2018/11/from-0-to-1000-instances-how-serverless-providers-scale-queue-processing/</link>
      <pubDate>Mon, 19 Nov 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/11/from-0-to-1000-instances-how-serverless-providers-scale-queue-processing/</guid>
      <description>&lt;p&gt;Whenever I see a &amp;ldquo;Getting Started with Function-as-a-Service&amp;rdquo; tutorial, it usually shows off&#xA;a synchronous HTTP-triggered scenario. In my projects, though, I use a lot of asynchronous&#xA;functions triggered by a queue or an event stream.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless: Cold Start War</title>
      <link>https://mikhail.io/2018/08/serverless-cold-start-war/</link>
      <pubDate>Thu, 30 Aug 2018 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2018/08/serverless-cold-start-war/</guid>
      <description>&lt;p&gt;&lt;em&gt;The newer and much more detailed cold start comparison is now available: &lt;a href=&#34;https://mikhail.io/serverless/coldstarts/&#34;&gt;Cold Starts in Serverless Functions&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&#xA;&lt;p&gt;Serverless cloud services are hot. Except when they are not :)&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
