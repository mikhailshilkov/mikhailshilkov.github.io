<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper Review on Mikhail Shilkov</title>
    <link>https://mikhail.io/tags/paper-review/</link>
    <description>Recent content in Paper Review on Mikhail Shilkov</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Mikhail Shilkov - All rights reserved</copyright>
    <lastBuildDate>Fri, 18 Jun 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://mikhail.io/tags/paper-review/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Eliminate Cold Starts by Predicting Invocations of Serverless Functions</title>
      <link>https://mikhail.io/2021/06/eliminate-cold-starts-by-predicting-invocations-of-serverless-functions/</link>
      <pubDate>Fri, 18 Jun 2021 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2021/06/eliminate-cold-starts-by-predicting-invocations-of-serverless-functions/</guid>
      <description>&lt;p&gt;Developers and decision-makers often mention &lt;a href=&#34;https://mikhail.io/serverless/coldstarts/&#34;&gt;cold starts&lt;/a&gt; as a significant drawback of serverless functions. Cloud providers continually invest in reducing the latency of a cold start, but they haven&amp;rsquo;t done much to prevent them altogether. The most common technique is to keep a worker alive for 10-20 minutes after each request, hoping that another request comes in and benefits from the warm instance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Emerging Landscape of Edge-Computing</title>
      <link>https://mikhail.io/2020/07/emerging-landscape-of-edge-computing/</link>
      <pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2020/07/emerging-landscape-of-edge-computing/</guid>
      <description>&lt;p&gt;While I have a good understanding of what cloud computing is, &amp;ldquo;edge computing&amp;rdquo; has remained vague. What &lt;em&gt;is&lt;/em&gt; edge computing, and what are the primary use cases in the world today?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Eliminate Cold Starts by Predicting Invocations of Serverless Functions</title>
      <link>https://mikhail.io/2020/06/eliminate-cold-starts-by-predicting-invocations-of-serverless-functions/</link>
      <pubDate>Thu, 18 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2020/06/eliminate-cold-starts-by-predicting-invocations-of-serverless-functions/</guid>
      <description>&lt;p&gt;Developers and decision-makers often mention &lt;a href=&#34;https://mikhail.io/serverless/coldstarts/&#34;&gt;cold starts&lt;/a&gt; as a significant drawback of serverless functions. Cloud providers continually invest in reducing the latency of a cold start, but they haven&amp;rsquo;t done much to prevent them altogether. The most common technique is to keep a worker alive for 10-20 minutes after each request, hoping that another request comes in and benefits from the warm instance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless in the Wild: Azure Functions Production Usage Statistics</title>
      <link>https://mikhail.io/2020/05/serverless-in-the-wild-azure-functions-usage-stats/</link>
      <pubDate>Tue, 05 May 2020 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2020/05/serverless-in-the-wild-azure-functions-usage-stats/</guid>
      <description>&lt;p&gt;Microsoft Azure and Microsoft Research &lt;a href=&#34;https://arxiv.org/pdf/2003.03423.pdf&#34;&gt;released&lt;/a&gt; a paper called &amp;ldquo;Serverless in the Wild: Characterizing and Optimizing the Serverless Workload at a Large Cloud Provider&amp;rdquo;. In part 1 of the paper, they revealed some insightful statistics about the actual production usage of Azure Functions for two weeks in summer 2019.&lt;/p&gt;</description>
    </item>
    <item>
      <title>InfiniCache: Distributed Cache on Top of AWS Lambda (paper review)</title>
      <link>https://mikhail.io/2020/03/infinicache-distributed-cache-on-aws-lambda/</link>
      <pubDate>Tue, 10 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://mikhail.io/2020/03/infinicache-distributed-cache-on-aws-lambda/</guid>
      <description>&lt;p&gt;&amp;ldquo;InfiniCache: Exploiting Ephemeral Serverless Functions to Build a Cost-Effective Memory Cache&amp;rdquo; by Ao Wang, et al. (&lt;a href=&#34;https://www.usenix.org/conference/fast20/presentation/wang-ao&#34;&gt;link&lt;/a&gt;) is a recently published paper which describes a prototype of a serverless distributed caching system sitting atop AWS Lambda.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
